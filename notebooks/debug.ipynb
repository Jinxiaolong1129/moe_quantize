{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-06T16:59:24.195146Z",
     "start_time": "2024-08-06T16:59:24.189703Z"
    }
   },
   "source": [
    "import math\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from colossalai.moe.layers import SparseMLP\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from transformers import LlamaConfig"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:59:24.212445Z",
     "start_time": "2024-08-06T16:59:24.198652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OpenMoeConfig(LlamaConfig):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_experts: int,\n",
    "            moe_layer_interval: int,\n",
    "            router_topk: int = 2,\n",
    "            router_capacity_factor_train: float = 1.25,\n",
    "            router_capacity_factor_eval: float = 2.0,\n",
    "            router_min_capacity: int = 4,\n",
    "            router_noisy_policy: str = None,\n",
    "            router_drop_tks: bool = True,\n",
    "            router_aux_loss_factor: float = 0.01,\n",
    "            router_z_loss_factor: float = 0.0001,\n",
    "            mlp_gated: bool = True,\n",
    "            label_smoothing: float = 0.001,\n",
    "            z_loss_factor: float = 0.01,\n",
    "            enable_load_balance: bool = False,\n",
    "            load_balance_tolerance: float = 0.1,\n",
    "            load_balance_beam_width: int = 8,\n",
    "            load_balance_group_swap_factor: float = 0.4,\n",
    "            enable_kernel: bool = False,\n",
    "            enable_comm_overlap: bool = False,\n",
    "            enable_hierarchical_alltoall: bool = False,\n",
    "            **kwargs\n",
    "    ):\n",
    "        self.num_experts = num_experts\n",
    "        self.moe_layer_interval = moe_layer_interval\n",
    "        self.router_topk = router_topk\n",
    "        self.router_capacity_factor_train = router_capacity_factor_train\n",
    "        self.router_capacity_factor_eval = router_capacity_factor_eval\n",
    "        self.router_min_capacity = router_min_capacity\n",
    "        self.router_noisy_policy = router_noisy_policy\n",
    "        self.router_drop_tks = router_drop_tks\n",
    "        self.router_aux_loss_factor = router_aux_loss_factor\n",
    "        self.router_z_loss_factor = router_z_loss_factor\n",
    "        self.mlp_gated = mlp_gated\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.z_loss_factor = z_loss_factor\n",
    "        self.enable_load_balance = enable_load_balance\n",
    "        self.load_balance_tolerance = load_balance_tolerance\n",
    "        self.load_balance_beam_width = load_balance_beam_width\n",
    "        self.load_balance_group_swap_factor = load_balance_group_swap_factor\n",
    "        self.enable_kernel = enable_kernel\n",
    "        self.enable_comm_overlap = enable_comm_overlap\n",
    "        self.enable_hierarchical_alltoall = enable_hierarchical_alltoall\n",
    "\n",
    "        super().__init__(**kwargs)"
   ],
   "id": "ebca48f96c448f69",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:10:42.453313Z",
     "start_time": "2024-08-06T17:10:42.443737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def swiglu_act_fn(x):\n",
    "    \"\"\"Gated linear unit activation function.\n",
    "    Args:\n",
    "        x : input array\n",
    "        axis: the axis along which the split should be computed (default: -1)\n",
    "    \"\"\"\n",
    "    size = x.shape[-1]\n",
    "    assert size % 2 == 0, \"axis size must be divisible by 2\"\n",
    "    x1, x2 = torch.split(x, size // 2, -1)\n",
    "    return x1 * (x2 * torch.sigmoid(x2))\n",
    "\n",
    "\n",
    "class OpenMoeMLP(torch.nn.Module):\n",
    "    def __init__(self, config: OpenMoeConfig):\n",
    "        super().__init__()\n",
    "        assert config.hidden_act==\"swiglu\"\n",
    "        self.ffn_dim = config.intermediate_size\n",
    "        self.hidden_dim = config.hidden_size\n",
    "\n",
    "        self.gate_proj = nn.Linear(self.hidden_dim, self.ffn_dim * 2, bias=False)\n",
    "        self.up_proj = nn.Linear(self.hidden_dim, self.ffn_dim, bias=False)\n",
    "        self.down_proj = nn.Linear(self.ffn_dim, self.hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        return self.down_proj(swiglu_act_fn(self.gate_proj(hidden_states)) * self.up_proj(hidden_states))\n",
    "\n"
   ],
   "id": "7e94c9605d320566",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:19:30.562303Z",
     "start_time": "2024-08-06T17:19:30.538983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def moe_cumsum(inputs: torch.Tensor):\n",
    "    return torch.cumsum(inputs, dim=0) - 1\n",
    "\n",
    "class OpenMoeTop2Router(torch.nn.Module):\n",
    "    def __init__(self, config: OpenMoeConfig):\n",
    "        super().__init__()\n",
    "        assert config.router_topk == 2\n",
    "        self.k_value = 2\n",
    "        self.capacity_factor_train = config.router_capacity_factor_train\n",
    "        self.capacity_factor_eval = config.router_capacity_factor_eval\n",
    "        self.min_capacity = config.router_min_capacity\n",
    "        self.drop_tks = config.router_drop_tks\n",
    "\n",
    "    def get_capacity(self, logits_shape):\n",
    "        capacity_factor = self.capacity_factor_train if self.training else self.capacity_factor_eval\n",
    "        capacity = math.floor(self.k_value * capacity_factor * logits_shape[-2] / logits_shape[-1])\n",
    "        capacity += capacity % 2\n",
    "        capacity = max(capacity, self.min_capacity)\n",
    "        assert capacity > 0\n",
    "        return int(capacity)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> Tuple:\n",
    "        assert inputs.dtype == torch.float, \"Router input should be FP32\"\n",
    "\n",
    "        probs = F.softmax(inputs, dim=-1)\n",
    "        num_experts = probs.size(-1)\n",
    "        capacity = self.get_capacity(inputs.shape)\n",
    "\n",
    "        top1_idx = torch.argmax(probs, dim=-1)\n",
    "        mask1 = F.one_hot(top1_idx, num_classes=num_experts).to(torch.int32)\n",
    "        logits_except1 = probs.masked_fill(mask1.bool(), float(\"-inf\"))\n",
    "        top2_idx = torch.argmax(logits_except1, dim=-1)\n",
    "        mask2 = F.one_hot(top2_idx, num_classes=num_experts).to(torch.int32)\n",
    "\n",
    "        rank1 = moe_cumsum(mask1)  # rank1: [s, e]\n",
    "        rank2 = moe_cumsum(mask2)\n",
    "        rank2 += torch.sum(mask1, dim=-2, keepdim=True)\n",
    "\n",
    "        mask1 *= torch.lt(rank1, capacity)\n",
    "        mask2 *= torch.lt(rank2, capacity)\n",
    "        used_capacity = mask1.sum(dim=0) + mask2.sum(dim=0)\n",
    "\n",
    "        rank1 = torch.sum(mask1 * rank1, dim=-1)\n",
    "        rank2 = torch.sum(mask2 * rank2, dim=-1)\n",
    "\n",
    "        weight1 = mask1 * probs.type_as(inputs)\n",
    "        weight2 = mask2 * probs.type_as(inputs)\n",
    "\n",
    "        cb_weight = torch.zeros(inputs.shape + (capacity,), device=inputs.device)\n",
    "        sec_mask = torch.zeros_like(cb_weight, dtype=torch.bool)\n",
    "        indices = torch.arange(0, inputs.shape[0], device=inputs.device)\n",
    "        cb_weight[indices, top1_idx[indices], rank1[indices]] += weight1[indices, top1_idx[indices]]\n",
    "        cb_weight[indices, top2_idx[indices], rank2[indices]] += weight2[indices, top2_idx[indices]]\n",
    "        sec_mask[indices, top1_idx[indices], rank1[indices]] |= mask1.bool()[indices, top1_idx[indices]]\n",
    "        sec_mask[indices, top2_idx[indices], rank2[indices]] |= mask2.bool()[indices, top2_idx[indices]]\n",
    "\n",
    "        return used_capacity, cb_weight, sec_mask"
   ],
   "id": "de72a4ccdd100557",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:20:23.760358Z",
     "start_time": "2024-08-06T17:20:23.746719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OpenMoeSparseMLP(torch.nn.Module):\n",
    "    def __init__(self, config: OpenMoeConfig):\n",
    "        super().__init__()\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.intermediate_size = config.intermediate_size\n",
    "        self.num_experts = config.num_experts\n",
    "\n",
    "        self.gate = torch.nn.Linear(self.hidden_size, config.num_experts, bias=False)\n",
    "\n",
    "        self.experts = nn.ModuleList([OpenMoeMLP(config) for _ in range(self.num_experts)])\n",
    "        self.router = OpenMoeTop2Router(config)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        # reshape the input tokens\n",
    "        tokens = hidden_states.reshape(-1, self.hidden_size)\n",
    "        inputs = hidden_states\n",
    "\n",
    "        # the data type of the inputs in the gating should be fp32\n",
    "        fp32_input = tokens.to(torch.float)\n",
    "        self.gate = self.gate.to(torch.float)\n",
    "        gate_output = self.gate(fp32_input)\n",
    "\n",
    "        used_capacity, *route_result_list = self.router(inputs=gate_output)\n",
    "\n",
    "        sec_mask_f = route_result_list[1].type_as(inputs)\n",
    "        dispatch_data = torch.matmul(sec_mask_f.permute(1, 2, 0), tokens)\n",
    "\n",
    "        expert_output = self._local_process(dispatch_data)\n",
    "\n",
    "        combine_weights = route_result_list[0].type_as(inputs)\n",
    "        combine_weights = combine_weights.view(combine_weights.shape[0], -1)\n",
    "        expert_output = expert_output.view(-1, expert_output.shape[-1])\n",
    "        ans = torch.matmul(combine_weights, expert_output)\n",
    "\n",
    "        ans = ans.reshape(inputs.shape)\n",
    "        return ans\n",
    "\n",
    "    def _local_process(self, expert_in: torch.Tensor) -> torch.Tensor:\n",
    "        expert_in = expert_in.unsqueeze(0)\n",
    "        x = expert_in\n",
    "\n",
    "        # Copied from colossalai MLPExperts class\n",
    "        e = x.size(1)\n",
    "        h = x.size(-1)\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "        inshape = x.shape\n",
    "        x = x.reshape(e, -1, h)\n",
    "\n",
    "        x = [self.experts[i](x[i]) for i in range(e)]\n",
    "\n",
    "        x = torch.cat([x[i].unsqueeze(0) for i in range(e)], dim=0)\n",
    "        x = x.reshape(inshape)\n",
    "        x = x.transpose(0, 1).contiguous()\n",
    "\n",
    "        expert_out = x\n",
    "        return expert_out\n",
    "\n"
   ],
   "id": "f40caf5a3b5c474",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:20:24.130024Z",
     "start_time": "2024-08-06T17:20:24.123511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hf_config = OpenMoeConfig(\n",
    "    moe_layer_interval=6,\n",
    "    num_experts=8,\n",
    "    hidden_size=16,\n",
    "    intermediate_size=64,\n",
    "    router_top_k=2,\n",
    "    router_capacity_factor_train=1.25,\n",
    "    router_capacity_factor_eval=2.0,\n",
    "    router_min_capacity=4,\n",
    "    router_noisy_policy=None,\n",
    "    router_drop_tks=True,\n",
    "    mlp_activation='swiglu',\n",
    "    mlp_gated=True,\n",
    "    enable_load_balance=False,\n",
    "    load_balance_tolerance=0.1,\n",
    "    load_balance_beam_width=8,\n",
    "    load_balance_group_swap_factor=0.4,\n",
    "    enable_kernel=False,\n",
    "    enable_comm_overlap=False,\n",
    ")"
   ],
   "id": "8cef6511aaceea68",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:20:24.261762Z",
     "start_time": "2024-08-06T17:20:24.252629Z"
    }
   },
   "cell_type": "code",
   "source": "hf_moe_layer = OpenMoeSparseMLP(hf_config)",
   "id": "11163b3633acef90",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:20:24.386201Z",
     "start_time": "2024-08-06T17:20:24.374576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "moe_layer = SparseMLP(\n",
    "    num_experts=8,\n",
    "    hidden_size=16,\n",
    "    intermediate_size=64,\n",
    "    router_top_k=2,\n",
    "    router_capacity_factor_train=1.25,\n",
    "    router_capacity_factor_eval=2.0,\n",
    "    router_min_capacity=4,\n",
    "    router_noisy_policy=None,\n",
    "    router_drop_tks=True,\n",
    "    mlp_activation='swiglu',\n",
    "    mlp_gated=True,\n",
    "    enable_load_balance=False,\n",
    "    load_balance_tolerance=0.1,\n",
    "    load_balance_beam_width=8,\n",
    "    load_balance_group_swap_factor=0.4,\n",
    "    enable_kernel=False,\n",
    "    enable_comm_overlap=False,\n",
    ")"
   ],
   "id": "66ac5b04576d0428",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:20:24.502190Z",
     "start_time": "2024-08-06T17:20:24.490040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(hf_config.num_experts):\n",
    "    hf_moe_layer.experts[i].gate_proj.weight.data.copy_(moe_layer.experts.wi_gate.data[i].t())\n",
    "    hf_moe_layer.experts[i].up_proj.weight.data.copy_(moe_layer.experts.wi_up.data[i].t())\n",
    "    hf_moe_layer.experts[i].down_proj.weight.data.copy_(moe_layer.experts.wo.data[i].t())\n",
    "    hf_moe_layer.gate.weight.data.copy_(moe_layer.gate_weight.data)"
   ],
   "id": "e6d4527e5f405502",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:20:24.652648Z",
     "start_time": "2024-08-06T17:20:24.646351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for n, p in moe_layer.named_parameters():\n",
    "    print(n, p.shape)"
   ],
   "id": "48e69f987d0b40f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gate_weight torch.Size([8, 16])\n",
      "experts.wi_gate torch.Size([8, 16, 128])\n",
      "experts.wi_up torch.Size([8, 16, 64])\n",
      "experts.wo torch.Size([8, 64, 16])\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:20:24.758078Z",
     "start_time": "2024-08-06T17:20:24.751823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for n, p in moe_layer.named_parameters():\n",
    "    print(n, p.shape)"
   ],
   "id": "f549ccc38edbd25b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gate_weight torch.Size([8, 16])\n",
      "experts.wi_gate torch.Size([8, 16, 128])\n",
      "experts.wi_up torch.Size([8, 16, 64])\n",
      "experts.wo torch.Size([8, 64, 16])\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:20:25.093158Z",
     "start_time": "2024-08-06T17:20:25.088399Z"
    }
   },
   "cell_type": "code",
   "source": "input_hidden_states = torch.randn(4, 12, 16)",
   "id": "c76ab1c7970210f6",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:20:25.555522Z",
     "start_time": "2024-08-06T17:20:25.544547Z"
    }
   },
   "cell_type": "code",
   "source": "moe_layer(input_hidden_states).shape",
   "id": "d2a728f038c3eb2e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 12, 16])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:20:26.022466Z",
     "start_time": "2024-08-06T17:20:26.000560Z"
    }
   },
   "cell_type": "code",
   "source": "hf_moe_layer(input_hidden_states).shape",
   "id": "fed92f4967dd5e7d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 12, 16])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:20:52.702523Z",
     "start_time": "2024-08-06T17:20:52.679368Z"
    }
   },
   "cell_type": "code",
   "source": "torch.allclose(moe_layer(input_hidden_states), hf_moe_layer(input_hidden_states))",
   "id": "432a94ab26f90624",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T17:21:14.770379Z",
     "start_time": "2024-08-06T17:21:13.495983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(100):\n",
    "    input_hidden_states = torch.randn(11, 12, 16)\n",
    "    assert torch.allclose(moe_layer(input_hidden_states), hf_moe_layer(input_hidden_states))"
   ],
   "id": "fe58f6ffa8fdac69",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3595c4ac4aaa583e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
